{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "from utils import config\n",
    "from utils.nerf_trainer import NeRF\n",
    "from utils.nerf import get_nerf_model, render_rgb_depth\n",
    "from utils.data import *\n",
    "from utils.train_monitor import get_train_monitor\n",
    "from rendering import render_videos\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# setting seed for reproducibility\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_train_data = read_json(config.TRAIN_JSON)\n",
    "json_val_data = read_json(config.VAL_JSON)\n",
    "json_test_data = read_json(config.TEST_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, train_camera_to_world = get_image_c2w(jsonData=json_train_data,\n",
    "                                                         datasetPath=config.DATASET_PATH)\n",
    "train_images = GetImages(train_image_paths)\n",
    "\n",
    "val_image_paths, val_camera_to_world = get_image_c2w(jsonData=json_val_data,\n",
    "                                                     datasetPath=config.DATASET_PATH)\n",
    "val_images = GetImages(val_image_paths)\n",
    "test_image_paths, test_camera_to_world = get_image_c2w(jsonData=json_test_data,\n",
    "                                                       datasetPath=config.DATASET_PATH)\n",
    "test_images = GetImages(test_image_paths)\n",
    "\n",
    "# instantiate a object of our class used to load images from disk\n",
    "val_camera_to_world = np.array(val_camera_to_world)\n",
    "val_camera_to_world = tf.cast(val_camera_to_world, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_datasets = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "val_image_datasets = tf.data.Dataset.from_tensor_slices(val_images)\n",
    "test_image_datasets = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "train_pose_dataset = tf.data.Dataset.from_tensor_slices(train_camera_to_world)\n",
    "val_pose_datasets = tf.data.Dataset.from_tensor_slices(val_camera_to_world)\n",
    "test_pose_datasets = tf.data.Dataset.from_tensor_slices(test_camera_to_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rays_dataset = train_pose_dataset.map(map_fn, num_parallel_calls=config.AUTO)\n",
    "val_rays_dataset = val_pose_datasets.map(map_fn, num_parallel_calls=config.AUTO)\n",
    "test_rays_dataset = test_pose_datasets.map(map_fn, num_parallel_calls=config.AUTO)\n",
    "\n",
    "# zip the images and rays dataset together\n",
    "train_dataset = tf.data.Dataset.zip((train_image_datasets, train_rays_dataset))\n",
    "val_dataset = tf.data.Dataset.zip((val_image_datasets, val_rays_dataset,))\n",
    "test_dataset = tf.data.Dataset.zip((test_image_datasets, test_rays_dataset,))\n",
    "# build data input pipeline for train, val, and test datasets\n",
    "train_dataset = (\n",
    "    train_dataset\n",
    "    .shuffle(config.BATCH_SIZE,)\n",
    "    .batch(config.BATCH_SIZE, drop_remainder=True, num_parallel_calls=config.AUTO).\n",
    "    repeat(2)\n",
    "    .prefetch(config.AUTO)\n",
    ")\n",
    "val_dataset = (\n",
    "    val_dataset\n",
    "    .shuffle(config.BATCH_SIZE)\n",
    "    .batch(config.BATCH_SIZE, drop_remainder=True, num_parallel_calls=config.AUTO)\n",
    "    .repeat(2)\n",
    "    .prefetch(config.AUTO)\n",
    ")\n",
    "test_dataset = (\n",
    "    test_dataset\n",
    "    .batch(config.BATCH_SIZE)\n",
    "    .prefetch(config.AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_monitor_callback = get_train_monitor(\n",
    "    test_dataset, render_rgb_depth=render_rgb_depth, OUTPUT_IMAGE_PATH=config.OUTPUT_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = config.IMAGE_HEIGHT * config.IMAGE_WIDTH * config.NUM_SAMPLES\n",
    "nerf_model = get_nerf_model(num_layers=8, num_pos=num_pos)\n",
    "model = NeRF(nerf_model)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(), loss_fn=tf.keras.losses.MeanSquaredError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=config.EPOCHS,\n",
    "        # callbacks=[train_monitor_callback],\n",
    "\n",
    "    )\n",
    "    model.nerf_model.save(config.MODEL_PATH ,save_format='tf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(config.MODEL_PATH ,compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_videos(nerf_model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
