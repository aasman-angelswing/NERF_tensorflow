{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "from utils import config\n",
    "from utils.nerf_trainer import NeRF\n",
    "from utils.nerf import get_nerf_model, render_rgb_depth\n",
    "from utils.data import *\n",
    "from utils.config import create_dir\n",
    "from utils.train_monitor import get_train_monitor\n",
    "from visual import inference, create_gif\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# setting seed for reproducibility\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonTrainData = read_json(config.TRAIN_JSON)\n",
    "jsonValData = read_json(config.VAL_JSON)\n",
    "jsonTestData = read_json(config.TEST_JSON)\n",
    "focalLength = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImagePaths, trainC2Ws = get_image_c2w(jsonData=jsonTrainData,\n",
    "                                           datasetPath=config.DATASET_PATH)\n",
    "train_images = GetImages(trainImagePaths)\n",
    "\n",
    "valImagePaths, valC2Ws = get_image_c2w(jsonData=jsonValData,\n",
    "                                       datasetPath=config.DATASET_PATH)\n",
    "val_images = GetImages(valImagePaths)\n",
    "testImagePaths, testC2Ws = get_image_c2w(jsonData=jsonTestData,\n",
    "                                         datasetPath=config.DATASET_PATH)\n",
    "test_images = GetImages(testImagePaths)\n",
    "# instantiate a object of our class used to load images from disk\n",
    "valC2Ws = np.array(valC2Ws)\n",
    "valC2Ws = tf.cast(valC2Ws, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImageDs = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "valImageDs = tf.data.Dataset.from_tensor_slices(val_images)\n",
    "testImageDs = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "train_pose_ds = tf.data.Dataset.from_tensor_slices(trainC2Ws)\n",
    "val_pose_ds = tf.data.Dataset.from_tensor_slices(valC2Ws)\n",
    "test_pose_ds = tf.data.Dataset.from_tensor_slices(testC2Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRayDs = train_pose_ds.map(map_fn, num_parallel_calls=config.AUTO)\n",
    "valRayDs = val_pose_ds.map(map_fn, num_parallel_calls=config.AUTO)\n",
    "testRayDs = test_pose_ds.map(map_fn, num_parallel_calls=config.AUTO)\n",
    "\n",
    "# zip the images and rays dataset together\n",
    "trainDs = tf.data.Dataset.zip((trainImageDs, trainRayDs))\n",
    "valDs = tf.data.Dataset.zip((valImageDs, valRayDs,))\n",
    "testDs = tf.data.Dataset.zip((testImageDs, testRayDs,))\n",
    "# build data input pipeline for train, val, and test datasets\n",
    "trainDs = (\n",
    "    trainDs\n",
    "    .shuffle(config.BATCH_SIZE,)\n",
    "    .batch(config.BATCH_SIZE, drop_remainder=True, num_parallel_calls=config.AUTO).\n",
    "    repeat(2)\n",
    "    .prefetch(config.AUTO)\n",
    ")\n",
    "valDs = (\n",
    "    valDs\n",
    "    .shuffle(config.BATCH_SIZE)\n",
    "    .batch(config.BATCH_SIZE, drop_remainder=True, num_parallel_calls=config.AUTO)\n",
    "    .repeat(2)\n",
    "    .prefetch(config.AUTO)\n",
    ")\n",
    "testDs = (\n",
    "    testDs\n",
    "    .batch(config.BATCH_SIZE)\n",
    "    .prefetch(config.AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMonitorCallback = get_train_monitor(\n",
    "    testDs, render_rgb_depth=render_rgb_depth, OUTPUT_IMAGE_PATH=config.OUTPUT_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = config.IMAGE_HEIGHT * config.IMAGE_WIDTH * config.NUM_SAMPLES\n",
    "nerf_model = get_nerf_model(num_layers=8, num_pos=num_pos)\n",
    "model = NeRF(nerf_model)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(), loss_fn=tf.keras.losses.MeanSquaredError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    trainDs,\n",
    "    validation_data=valDs,\n",
    "    # batch_size=config.BATCH_SIZE,\n",
    "    epochs=config.EPOCHS,\n",
    "    callbacks=[trainMonitorCallback],\n",
    "    # steps_per_epoch=config.STEPS_PER_EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.nerf_model.save(config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gif(config.OUTPUT_IMAGE_PATH, \"training.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(nerf_model=model.nerf_model, render_rgb_depth=render_rgb_depth,\n",
    "          testDs=testDs, OUTPUT_INFERENCE_PATH=config.OUTPUT_INFERENCE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
